{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_TEST = \"exame-pulmao\"\n",
    "TRAIN_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA/\" + FOLDER_TEST\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-vidro/\" + FOLDER_TEST\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HCPA-vidro/\" + FOLDER_TEST\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA/\" + FOLDER_TEST\n",
    "\n",
    "# SUB_FILE = ['axis1', 'axis2']\n",
    "SUB_FILE = ['axis2']\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300 \n",
    "IMG_CHANNELS = 3\n",
    "SELECTED_MODEL = ''\n",
    "NUM_CLASSES = 2\n",
    "# DATA_FOLDER = '20200827/'\n",
    "DATA_FOLDER = '20200910/'\n",
    "LOG_FOLDER = 'logs/' + DATA_FOLDER\n",
    "TRAINING_FOLDER = 'training/' + DATA_FOLDER\n",
    "MODEL_FOLDER = 'models/' + DATA_FOLDER\n",
    "IMAGE_FOLDER = 'images/' + DATA_FOLDER\n",
    "\n",
    "STRUCTURE_DATASET_FOLDER = \"csv/input/\"+DATA_FOLDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    '''\n",
    "    Get all files (full path) contained in a PATH folder by specified search filter \n",
    "    '''\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(fold_number, cur_subfile, data_train, data_test):\n",
    "    ''' Creates and returns a dataframe with all the full paths (for slice) for train and test images. \n",
    "    Save it as log. \n",
    "    '''\n",
    "    dfs = []\n",
    "    train_images = {\"id\": [], \"label\": []}\n",
    "    validation_images = {\"id\": [], \"label\": []}\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            dic[\"id\"].extend(imgs_filename)\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "#     print(dfs)\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"logs/\"): \n",
    "        os.mkdir(\"logs/\")\n",
    "    if not os.path.exists(LOG_FOLDER): \n",
    "        os.mkdir(LOG_FOLDER)\n",
    "        \n",
    "    train_df.to_csv(\"{}/train{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "    validation_df.to_csv(\"{}/test{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"all\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(train_images[\"id\"])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(train_images[\"label\"])\n",
    "    for path, target in zip(train_images[\"id\"], train_images[\"label\"]):\n",
    "        if target!=show and show!=\"all\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\"all\":\"All Classifications's\",\n",
    "             \"healthy\":\"Healthy\",\n",
    "             \"covid\":\"Covid-19\"}\n",
    "    plt.title(\"100 Samples of {} Patients of the training set\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_gallery(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    )\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        class_mode=class_mode,\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg16_chico():\n",
    "    with tf.device('/GPU:0'):\n",
    "#         conv_base = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "        conv_base = get_base_model()\n",
    "\n",
    "        conv_base.trainable = True\n",
    "        set_trainable = False\n",
    "        for layer in conv_base.layers:\n",
    "            if layer.name == 'block1_conv1':\n",
    "                set_trainable = True\n",
    "            if set_trainable:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "        x = conv_base.output\n",
    "#         model = tf.keras.Sequential()\n",
    "#         model.add(conv_base)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#         model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "        preds = tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'softmax')(x)\n",
    "#         model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'sigmoid'))\n",
    "\n",
    "        model = tf.keras.Model(inputs=conv_base.input, outputs=preds)\n",
    "    \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return (model, 'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg16():\n",
    "    with tf.device('/GPU:0'):\n",
    "        conv_base = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        conv_base.trainable = True\n",
    "        set_trainable = False\n",
    "        for layer in conv_base.layers:\n",
    "            if layer.name == 'block1_conv1':\n",
    "                set_trainable = True\n",
    "            if set_trainable:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(conv_base)\n",
    "        model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return (model, 'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_resnet50():\n",
    "    with tf.device('/GPU:0'):\n",
    "        conv_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        conv_base.trainable = True\n",
    "#         set_trainable = False\n",
    "#         for layer in conv_base.layers:\n",
    "#             if layer.name == 'block1_conv1':\n",
    "#                 set_trainable = True\n",
    "#             if set_trainable:\n",
    "#                 layer.trainable = True\n",
    "#             else:\n",
    "#                 layer.trainable = False\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(conv_base)\n",
    "        model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "        model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return (model, 'resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, validation_df, epochs, fold, axis):\n",
    "    batch_size = 16\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "    validation_generator = get_data_generator(validation_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "\n",
    "    print(train_generator.class_indices)\n",
    "    print(validation_generator.class_indices)\n",
    "    \n",
    "    step_size_train = train_generator.n // train_generator.batch_size\n",
    "    step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = train_generator.n // 2\n",
    "        step_size_validation = validation_generator.n // 2\n",
    "        \n",
    "        \n",
    "    # callbacks, save each time\n",
    "    # training/20200827/vgg16/fold4/axis2\n",
    "    checkpoint_path = \"training/\"\n",
    "    if not os.path.exists(\"training/\"): \n",
    "        os.mkdir(\"training/\")\n",
    "    checkpoint_path = \"{}/\".format(TRAINING_FOLDER)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/fold{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "    \n",
    "    checkpoint_path = \"{}/{}/fold{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    # Save dict results of history and legend from current model\n",
    "    # models/20200827/vgg16/fold4/axis2/{history|legend}\n",
    "    if not os.path.exists(\"models/\"): \n",
    "        os.mkdir(\"models/\")\n",
    "    \n",
    "    model_dir = \"{}/\".format(MODEL_FOLDER)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}\".format(MODEL_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}/fold{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_dir = \"{}/{}/fold{}/{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    checkpoint_path = checkpoint_path + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 25 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        period=25)\n",
    "        \n",
    "    history = model.fit(train_generator, # X_Train\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=cp_callback\n",
    "                       )\n",
    "    \n",
    "    # Save last values\n",
    "    model.save_weights(checkpoint_dir+\"/my_checkpoint\")\n",
    "#     model.save(checkpoint_dir+\"/my_checkpoint\")\n",
    "    \n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = model_dir + 'history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    \n",
    "    # Save classes\n",
    "    print(train_generator.class_indices)\n",
    "    np.save(model_dir + 'legend', train_generator.class_indices)\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(history, sub_folder, fold, sel_model):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    \n",
    "    image_dir = \"images/\"\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/\".format(IMAGE_FOLDER)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(image_dir + 'accuracy', pad_inches=0.1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(image_dir + 'loss', orientation='portrait', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate model for data folders (patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_by_patient(model, patients, legend_file, axis):\n",
    "    results = []\n",
    "    for p in patients:\n",
    "        # for axis in SUB_FILE:\n",
    "        curr_dir = \"{}/{}/{}\".format(VALIDATION_IMG_SRC_FOLDER, p, axis)\n",
    "        # print(curr_dir)\n",
    "        imgs_filename = sorted(os.listdir(curr_dir))\n",
    "        test_filenames = imgs_filename[:]\n",
    "        test_df = pd.DataFrame({\n",
    "                'filename': test_filenames\n",
    "            })\n",
    "        nb_samples = test_df.shape[0]\n",
    "\n",
    "        test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_gen.flow_from_dataframe(\n",
    "                test_df, \n",
    "                curr_dir, \n",
    "                x_col='filename',\n",
    "                y_col=None,\n",
    "                class_mode=None,\n",
    "                target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                batch_size=16,\n",
    "                shuffle=False\n",
    "        )\n",
    "\n",
    "        predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))\n",
    "#         print(predict)\n",
    "#         test_df['category'] = [int(round(p[1])) for p in predict]\n",
    "        test_df['category'] = [np.where(pr == np.max(pr))[0][0] for pr in predict]\n",
    "        test_df['patient'] = p\n",
    "        test_df['axis'] = axis\n",
    "        results.append(test_df)\n",
    "\n",
    "    print('Axis: ', test_df['axis'][0])\n",
    "    df_result = pd.DataFrame(columns=['category', 'patient','count'])\n",
    "    for i,test_df in enumerate(results):\n",
    "        cur_patient = test_df['patient'][0]\n",
    "        if os.path.isfile(legend_file+'.npy'):\n",
    "            class_indices = np.load(legend_file+'.npy', allow_pickle=True).item()\n",
    "            class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "#             print(class_indices)\n",
    "            test_df['category'] = test_df['category'].replace(class_indices)\n",
    "        test_df['count'] = 1\n",
    "        test_df = test_df.groupby('category', as_index = False)['count'].count()\n",
    "        test_df['patient'] = cur_patient\n",
    "        df_result = df_result.append(test_df)\n",
    "#     print(df_result)\n",
    "    return df_result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model for 'axis1...n' and folds [ 1...N ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Train fold with 9348 images\n",
      "label\n",
      "NEGATIVE    2706\n",
      "POSITIVE    6642\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 2870 images\n",
      "label\n",
      "NEGATIVE     902\n",
      "POSITIVE    1968\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis2\n",
      "=====\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 10, 10, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10, 10, 1024)      2098176   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10, 10, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_15  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 26,737,538\n",
      "Trainable params: 26,684,418\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Found 9348 validated image filenames belonging to 2 classes.\n",
      "Found 2870 validated image filenames belonging to 2 classes.\n",
      "{'NEGATIVE': 0, 'POSITIVE': 1}\n",
      "{'NEGATIVE': 0, 'POSITIVE': 1}\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "584/584 [==============================] - 382s 653ms/step - loss: 0.0572 - accuracy: 0.9775 - val_loss: 1.1209 - val_accuracy: 0.3139\n",
      "Epoch 2/20\n",
      "584/584 [==============================] - 400s 684ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 1.5962 - val_accuracy: 0.6233\n",
      "Epoch 3/20\n",
      "584/584 [==============================] - 402s 688ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1099 - val_accuracy: 0.9686\n",
      "Epoch 4/20\n",
      "584/584 [==============================] - 402s 689ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1540 - val_accuracy: 0.9616\n",
      "Epoch 5/20\n",
      "584/584 [==============================] - 402s 689ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4368 - val_accuracy: 0.9169\n",
      "Epoch 6/20\n",
      "584/584 [==============================] - 402s 689ms/step - loss: 9.1866e-04 - accuracy: 0.9998 - val_loss: 0.1775 - val_accuracy: 0.9584\n",
      "Epoch 7/20\n",
      "584/584 [==============================] - 402s 688ms/step - loss: 2.0372e-04 - accuracy: 0.9999 - val_loss: 0.2171 - val_accuracy: 0.9459\n",
      "Epoch 8/20\n",
      "584/584 [==============================] - 402s 689ms/step - loss: 7.7123e-04 - accuracy: 0.9999 - val_loss: 0.0986 - val_accuracy: 0.9777\n",
      "Epoch 9/20\n",
      "584/584 [==============================] - 402s 689ms/step - loss: 8.1534e-06 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9759\n",
      "Epoch 10/20\n",
      "584/584 [==============================] - 406s 696ms/step - loss: 7.4602e-04 - accuracy: 0.9998 - val_loss: 0.3504 - val_accuracy: 0.9515\n",
      "Epoch 11/20\n",
      "584/584 [==============================] - 403s 691ms/step - loss: 2.5301e-07 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9550\n",
      "Epoch 12/20\n",
      "584/584 [==============================] - 407s 696ms/step - loss: 1.0338e-07 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9511\n",
      "Epoch 13/20\n",
      "584/584 [==============================] - 405s 693ms/step - loss: 5.8891e-05 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9836\n",
      "Epoch 14/20\n",
      "584/584 [==============================] - 406s 696ms/step - loss: 3.1834e-04 - accuracy: 0.9998 - val_loss: 0.1605 - val_accuracy: 0.9703\n",
      "Epoch 15/20\n",
      "584/584 [==============================] - 406s 696ms/step - loss: 8.5875e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9647\n",
      "Epoch 16/20\n",
      "584/584 [==============================] - 406s 696ms/step - loss: 3.4495e-08 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9665\n",
      "Epoch 17/20\n",
      "103/584 [====>.........................] - ETA: 4:53 - loss: 1.7612e-09 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "for axis in SUB_FILE:\n",
    "#     for n_fold in [1, 2, 3, 4, 5]:\n",
    "    for n_fold in [5]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_train = pd.read_csv(\"{}/train/train{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        train_df, validation_df = get_data_set(n_fold, axis, data_train, data_validation)\n",
    "        \n",
    "        print('\\n'+axis+'\\n=====')\n",
    "#         model, SELECTED_MODEL = get_model_vgg16()\n",
    "        model, SELECTED_MODEL = get_model_resnet50()\n",
    "        history = train_model(model, train_df, validation_df, EPOCHS, n_fold, axis)\n",
    "        \n",
    "        #Plot Results\n",
    "        plot_results(history, axis, n_fold, SELECTED_MODEL)\n",
    "        \n",
    "        # Test with other patients\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models!\n",
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, SELECTED_MODEL = get_model_resnet50()\n",
    "model, SELECTED_MODEL = get_model_vgg16()\n",
    "\n",
    "# model.load_weights('training/resnet50/5fold/axis1/my_checkpoint')\n",
    "fold = 1\n",
    "axis = 'axis1'\n",
    "legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "model.load_weights(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, fold, axis))\n",
    "\n",
    "# data_test =  ['C77', 'C117', 'C136', 'C80', 'C91', 'C104', 'C62', 'C147', 'C106', 'C68', 'C123', 'C99', 'C129']\n",
    "# HCPA\n",
    "# data_test = ['NEG-001', 'NEG-002', 'NEG-003', 'NEG-004', 'NEG-005', 'NEG-006', 'NEG-007', 'NEG-008', 'NEG-009', \n",
    "#              'NEG-010', 'NEG-011', 'NEG-012', 'NEG-013', 'NEG-014', 'NEG-015', 'TYP-002', 'TYP-003', 'TYP-004', \n",
    "#              'TYP-005', 'TYP-006', 'TYP-007', 'TYP-008', 'TYP-009', 'TYP-010', 'TYP-011', 'TYP-012', 'TYP-013', \n",
    "#              'TYP-014', 'TYP-015', 'TYP-016', 'TYP-017', 'TYP-018', 'TYP-019', 'TYP-020', 'TYP-021', 'TYP-022', \n",
    "#              'TYP-023', 'TYP-024', 'TYP-025', 'TYP-026', 'TYP-027', 'TYP-028', 'TYP-029', 'TYP-030', 'TYP-031']\n",
    "\n",
    "# HMV - CT Indeterminados - PCR Negativo\n",
    "# data_test = ['C8', 'C28', 'C30', 'C31', 'C34', 'C37', 'C38', 'C45', 'C47', 'C54', 'C68', 'C72', 'C84', 'C98', \n",
    "#              'C99', 'C109', 'C119', 'C123', 'C129', 'C139', 'C140', 'C148', 'C156']\n",
    "\n",
    "# HMV - CT Indeterminados - PCR Positivo\n",
    "# data_test = ['C40', 'C48', 'C57', 'C65', 'C97', 'C107', 'C128']\n",
    "\n",
    "# HMV - Atípicos\n",
    "# data_test = ['C9', 'C43', 'C55', 'C56', 'C58', 'C59', 'C64', 'C67', 'C70', 'C73', 'C81', 'C118', 'C122', 'C127', \n",
    "#              'C134', 'C141', 'C164']\n",
    "\n",
    "# HMV - CT Típico - PCR negativo\n",
    "# data_test = ['C71', 'C101', 'C143', 'C162'] \n",
    "\n",
    "# HMV - CT Negativo - PCR positivo\n",
    "data_test = ['C76', 'C105']\n",
    "\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HCPA/exame-pulmao\"\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV/exame-pulmao\"\n",
    "\n",
    "df = predictions_by_patient(model, data_test, legend_path, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "axis1\n",
      "=====\n",
      "\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 164 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis1\n",
      " category  patient count\n",
      " NEGATIVE     C106    82\n",
      " NEGATIVE     C120    82\n",
      " NEGATIVE      C52    82\n",
      " NEGATIVE      C61    82\n",
      " NEGATIVE      C86    82\n",
      " NEGATIVE      C89    82\n",
      " POSITIVE      C11    82\n",
      " POSITIVE     C131    82\n",
      " POSITIVE     C154    82\n",
      " NEGATIVE     C161    82\n",
      " POSITIVE      C26    82\n",
      " POSITIVE      C33    82\n",
      " POSITIVE      C36    82\n",
      " POSITIVE      C39    82\n",
      " POSITIVE      C75    82\n",
      " POSITIVE      C77   164\n",
      " POSITIVE      C91    82\n",
      " POSITIVE      C94    82\n",
      " NEGATIVE  NEG-002    62\n",
      " NEGATIVE  NEG-007    82\n",
      " POSITIVE  NEG-011    82\n",
      " POSITIVE  TYP-002    75\n",
      " POSITIVE  TYP-004    82\n",
      " NEGATIVE  TYP-005    71\n",
      " POSITIVE  TYP-007    82\n",
      " POSITIVE  TYP-008    82\n",
      " POSITIVE  TYP-021    82\n",
      " POSITIVE  TYP-024    82\n",
      " POSITIVE  TYP-027    78\n",
      "\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis1\n",
      " category  patient count\n",
      " NEGATIVE     C100    82\n",
      " NEGATIVE     C108    82\n",
      " NEGATIVE     C147    82\n",
      " NEGATIVE     C152    82\n",
      " NEGATIVE      C24    82\n",
      " NEGATIVE      C87    82\n",
      " POSITIVE     C111    82\n",
      " NEGATIVE     C115    78\n",
      " POSITIVE     C116    78\n",
      " POSITIVE     C121    82\n",
      " POSITIVE     C132    82\n",
      " POSITIVE      C14    82\n",
      " POSITIVE     C144    82\n",
      " POSITIVE     C146    82\n",
      " POSITIVE     C157    82\n",
      " NEGATIVE     C160    82\n",
      " POSITIVE      C27    82\n",
      " POSITIVE      C93    46\n",
      " NEGATIVE  NEG-004    82\n",
      " NEGATIVE  NEG-012    79\n",
      " NEGATIVE  NEG-015    82\n",
      " POSITIVE  TYP-003    79\n",
      " POSITIVE  TYP-011    82\n",
      " POSITIVE  TYP-012    81\n",
      " POSITIVE  TYP-018    82\n",
      " NEGATIVE  TYP-020    73\n",
      " POSITIVE  TYP-025    82\n",
      " POSITIVE  TYP-030    82\n",
      " POSITIVE  TYP-031    82\n",
      "\n",
      "\n",
      "\n",
      "Fold 3\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis1\n",
      " category  patient count\n",
      " NEGATIVE     C102    82\n",
      " NEGATIVE     C159    82\n",
      " NEGATIVE      C29    82\n",
      " NEGATIVE      C46    82\n",
      " NEGATIVE      C50    82\n",
      " POSITIVE     C103    82\n",
      " POSITIVE     C112    82\n",
      " NEGATIVE     C114    82\n",
      " POSITIVE      C12    82\n",
      " POSITIVE     C158    82\n",
      " POSITIVE      C18    82\n",
      " POSITIVE      C20    82\n",
      " POSITIVE      C35    82\n",
      " POSITIVE      C41    82\n",
      " POSITIVE      C44    82\n",
      " NEGATIVE      C82    82\n",
      " POSITIVE      C83    82\n",
      " POSITIVE      C88    82\n",
      " POSITIVE      C90    82\n",
      " NEGATIVE  NEG-010    75\n",
      " NEGATIVE  NEG-014    82\n",
      " POSITIVE  TYP-010    82\n",
      " POSITIVE  TYP-016    82\n",
      " POSITIVE  TYP-017    82\n",
      " POSITIVE  TYP-019    82\n",
      " POSITIVE  TYP-023    82\n",
      "\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis1\n",
      " category  patient count\n",
      " NEGATIVE       C3    82\n",
      " NEGATIVE     C104    82\n",
      " NEGATIVE      C62    82\n",
      " NEGATIVE      C92    82\n",
      " POSITIVE     C113    73\n",
      " POSITIVE      C13    82\n",
      " NEGATIVE     C133    82\n",
      " POSITIVE     C136    82\n",
      " POSITIVE     C145    68\n",
      " POSITIVE     C150    82\n",
      " POSITIVE      C17    82\n",
      " POSITIVE      C23    82\n",
      " POSITIVE      C32    82\n",
      " POSITIVE      C49    82\n",
      " POSITIVE      C51    82\n",
      " POSITIVE      C60    82\n",
      " POSITIVE      C69    82\n",
      " POSITIVE      C74    82\n",
      " POSITIVE      C79    82\n",
      " POSITIVE      C80    82\n",
      " POSITIVE      C85    82\n",
      " POSITIVE      C96    82\n",
      " NEGATIVE  NEG-003    82\n",
      " NEGATIVE  NEG-006    82\n",
      " NEGATIVE  NEG-008    82\n",
      " NEGATIVE  NEG-013    82\n",
      " POSITIVE  TYP-006    82\n",
      " POSITIVE  TYP-014    55\n",
      " NEGATIVE  TYP-028    77\n",
      "\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 164 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis1\n",
      " category  patient count\n",
      " NEGATIVE       C5    82\n",
      " NEGATIVE     C126    82\n",
      " NEGATIVE     C137    82\n",
      " NEGATIVE      C22    82\n",
      " NEGATIVE      C42    56\n",
      " NEGATIVE      C63    82\n",
      " NEGATIVE      C66    82\n",
      " NEGATIVE      C78    82\n",
      " POSITIVE     C110    82\n",
      " POSITIVE     C117    82\n",
      " POSITIVE     C124    82\n",
      " POSITIVE     C125    82\n",
      " POSITIVE     C130   164\n",
      " POSITIVE     C135    82\n",
      " POSITIVE     C138    82\n",
      " POSITIVE     C142    82\n",
      " POSITIVE     C149    82\n",
      " POSITIVE      C15    82\n",
      " POSITIVE     C151    82\n",
      " POSITIVE     C155    82\n",
      " POSITIVE      C16    82\n",
      " POSITIVE     C163    82\n",
      " POSITIVE      C19    82\n",
      " POSITIVE      C21    82\n",
      " POSITIVE      C25    82\n",
      " NEGATIVE  NEG-001    82\n",
      " NEGATIVE  NEG-005    82\n",
      " NEGATIVE  NEG-009    82\n",
      " POSITIVE  TYP-009    68\n",
      " POSITIVE  TYP-013    82\n",
      " POSITIVE  TYP-015    82\n",
      " POSITIVE  TYP-022    82\n",
      " POSITIVE  TYP-026    82\n",
      " POSITIVE  TYP-029    82\n",
      "\n",
      "axis2\n",
      "=====\n",
      "\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 164 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis2\n",
      " category  patient count\n",
      " NEGATIVE     C106    82\n",
      " NEGATIVE     C120    82\n",
      " NEGATIVE      C52    82\n",
      " NEGATIVE      C61    82\n",
      " NEGATIVE      C86    82\n",
      " NEGATIVE      C89    82\n",
      " POSITIVE      C11    80\n",
      " POSITIVE     C131    82\n",
      " POSITIVE     C154    82\n",
      " NEGATIVE     C161    72\n",
      " POSITIVE      C26    82\n",
      " POSITIVE      C33    82\n",
      " POSITIVE      C36    82\n",
      " POSITIVE      C39    82\n",
      " POSITIVE      C75    82\n",
      " POSITIVE      C77   164\n",
      " POSITIVE      C91    82\n",
      " POSITIVE      C94    82\n",
      " NEGATIVE  NEG-002    82\n",
      " NEGATIVE  NEG-007    82\n",
      " POSITIVE  NEG-011    82\n",
      " POSITIVE  TYP-002    82\n",
      " POSITIVE  TYP-004    82\n",
      " NEGATIVE  TYP-005    75\n",
      " POSITIVE  TYP-007    82\n",
      " POSITIVE  TYP-008    82\n",
      " POSITIVE  TYP-021    82\n",
      " POSITIVE  TYP-024    82\n",
      " NEGATIVE  TYP-027    80\n",
      "\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis2\n",
      " category  patient count\n",
      " NEGATIVE     C100    82\n",
      " NEGATIVE     C108    82\n",
      " NEGATIVE     C147    82\n",
      " NEGATIVE     C152    82\n",
      " POSITIVE      C24    80\n",
      " NEGATIVE      C87    82\n",
      " POSITIVE     C111    82\n",
      " POSITIVE     C115    82\n",
      " POSITIVE     C116    82\n",
      " POSITIVE     C121    78\n",
      " POSITIVE     C132    82\n",
      " POSITIVE      C14    82\n",
      " POSITIVE     C144    82\n",
      " POSITIVE     C146    82\n",
      " POSITIVE     C157    82\n",
      " POSITIVE     C160    53\n",
      " POSITIVE      C27    82\n",
      " POSITIVE      C93    81\n",
      " NEGATIVE  NEG-004    82\n",
      " POSITIVE  NEG-012    82\n",
      " NEGATIVE  NEG-015    82\n",
      " POSITIVE  TYP-003    82\n",
      " POSITIVE  TYP-011    82\n",
      " POSITIVE  TYP-012    82\n",
      " POSITIVE  TYP-018    82\n",
      " POSITIVE  TYP-020    82\n",
      " POSITIVE  TYP-025    82\n",
      " POSITIVE  TYP-030    82\n",
      " POSITIVE  TYP-031    82\n",
      "\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_12  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis2\n",
      " category  patient count\n",
      " NEGATIVE     C102    82\n",
      " NEGATIVE     C159    82\n",
      " NEGATIVE      C29    82\n",
      " NEGATIVE      C46    82\n",
      " NEGATIVE      C50    81\n",
      " POSITIVE     C103    82\n",
      " POSITIVE     C112    79\n",
      " NEGATIVE     C114    82\n",
      " POSITIVE      C12    82\n",
      " POSITIVE     C158    82\n",
      " POSITIVE      C18    82\n",
      " POSITIVE      C20    82\n",
      " POSITIVE      C35    82\n",
      " POSITIVE      C41    82\n",
      " POSITIVE      C44    82\n",
      " NEGATIVE      C82    82\n",
      " POSITIVE      C83    82\n",
      " POSITIVE      C88    81\n",
      " POSITIVE      C90    82\n",
      " NEGATIVE  NEG-010    82\n",
      " NEGATIVE  NEG-014    82\n",
      " POSITIVE  TYP-010    82\n",
      " POSITIVE  TYP-016    82\n",
      " POSITIVE  TYP-017    82\n",
      " POSITIVE  TYP-019    82\n",
      " POSITIVE  TYP-023    82\n",
      "\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_13  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis2\n",
      " category  patient count\n",
      " NEGATIVE       C3    82\n",
      " NEGATIVE     C104    82\n",
      " NEGATIVE      C62    82\n",
      " NEGATIVE      C92    82\n",
      " POSITIVE     C113    82\n",
      " POSITIVE      C13    82\n",
      " NEGATIVE     C133    55\n",
      " POSITIVE     C136    82\n",
      " POSITIVE     C145    82\n",
      " POSITIVE     C150    82\n",
      " POSITIVE      C17    82\n",
      " POSITIVE      C23    82\n",
      " POSITIVE      C32    82\n",
      " POSITIVE      C49    76\n",
      " POSITIVE      C51    82\n",
      " POSITIVE      C60    82\n",
      " POSITIVE      C69    82\n",
      " POSITIVE      C74    82\n",
      " POSITIVE      C79    82\n",
      " POSITIVE      C80    82\n",
      " POSITIVE      C85    82\n",
      " POSITIVE      C96    82\n",
      " NEGATIVE  NEG-003    82\n",
      " NEGATIVE  NEG-006    82\n",
      " NEGATIVE  NEG-008    82\n",
      " NEGATIVE  NEG-013    82\n",
      " POSITIVE  TYP-006    82\n",
      " POSITIVE  TYP-014    82\n",
      " POSITIVE  TYP-028    82\n",
      "\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 164 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Found 82 validated image filenames.\n",
      "Axis:  axis2\n",
      " category  patient count\n",
      " NEGATIVE       C5    82\n",
      " NEGATIVE     C126    82\n",
      " NEGATIVE     C137    82\n",
      " NEGATIVE      C22    82\n",
      " POSITIVE      C42    77\n",
      " NEGATIVE      C63    81\n",
      " NEGATIVE      C66    82\n",
      " NEGATIVE      C78    82\n",
      " POSITIVE     C110    82\n",
      " POSITIVE     C117    82\n",
      " POSITIVE     C124    82\n",
      " POSITIVE     C125    82\n",
      " POSITIVE     C130   164\n",
      " POSITIVE     C135    82\n",
      " POSITIVE     C138    82\n",
      " POSITIVE     C142    82\n",
      " POSITIVE     C149    82\n",
      " POSITIVE      C15    82\n",
      " POSITIVE     C151    82\n",
      " POSITIVE     C155    79\n",
      " POSITIVE      C16    82\n",
      " POSITIVE     C163    82\n",
      " POSITIVE      C19    82\n",
      " POSITIVE      C21    82\n",
      " POSITIVE      C25    82\n",
      " NEGATIVE  NEG-001    82\n",
      " NEGATIVE  NEG-005    82\n",
      " NEGATIVE  NEG-009    82\n",
      " POSITIVE  TYP-009    82\n",
      " POSITIVE  TYP-013    47\n",
      " POSITIVE  TYP-015    82\n",
      " POSITIVE  TYP-022    82\n",
      " POSITIVE  TYP-026    82\n",
      " POSITIVE  TYP-029    82\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "HMV\n",
    "'''\n",
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        \n",
    "#         model, SELECTED_MODEL = get_model_resnet50()\n",
    "        model, SELECTED_MODEL = get_model_vgg16()\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        model.load_weights(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        print(df[idx][['category', 'patient', 'count']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HCPA\n",
    "'''\n",
    "data_test = ['NEG-001', 'NEG-002', 'NEG-003', 'NEG-004', 'NEG-005', 'NEG-006', 'NEG-007', 'NEG-008', 'NEG-009', \n",
    "             'NEG-010', 'NEG-011', 'NEG-012', 'NEG-013', 'NEG-014', 'NEG-015', 'TYP-002', 'TYP-003', 'TYP-004', \n",
    "             'TYP-005', 'TYP-006', 'TYP-007', 'TYP-008', 'TYP-009', 'TYP-010', 'TYP-011', 'TYP-012', 'TYP-013', \n",
    "             'TYP-014', 'TYP-015', 'TYP-016', 'TYP-017', 'TYP-018', 'TYP-019', 'TYP-020', 'TYP-021', 'TYP-022', \n",
    "             'TYP-023', 'TYP-024', 'TYP-025', 'TYP-026', 'TYP-027', 'TYP-028', 'TYP-029', 'TYP-030', 'TYP-031']\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "#         model, SELECTED_MODEL = get_model_resnet50()\n",
    "        model, SELECTED_MODEL = get_model_vgg16()\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        model.load_weights(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_test, legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        print(df[idx][['category', 'patient', 'count']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "#         model, SELECTED_MODEL = get_model_resnet50()\n",
    "        df = pd.read_csv(\"{}/{}/fold{}/{}/history.csv\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        print(max(df['val_accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
