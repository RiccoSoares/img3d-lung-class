{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('csv/exames.csv')\n",
    "data_pos = data[data.covid == 'POSITIVE']\n",
    "data_neg = data[data.covid == 'NEGATIVE']\n",
    "data_pos = data_pos.reset_index(drop=True)\n",
    "data_neg = data_neg.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "#TRAIN_IMG_SRC_FOLDER = '/./lung-segmentation/uniq'\n",
    "# FOLDER_TEST = \"3D-views-script\"\n",
    "FOLDER_TEST = \"exame-pulmao\"\n",
    "TRAIN_IMG_SRC_FOLDER = \"/ssd/share/Classificacao/Abordagem3D-Comba/input/\" + FOLDER_TEST\n",
    "# LIST_IMG_FOLDERS = [\"C21\", ]\n",
    "# TRAIN_IMG_FOLDERS = { \"C21\": \"positivo\", \"C23\": \"egativo\" }\n",
    "\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/ssd/share/Classificacao/Abordagem3D-Comba/input/\" + FOLDER_TEST\n",
    "VALIDATION_IMG_FOLDERS = { #     \"exame5\": \"healthy\", \"exame15\": \"covid\", \"exame10\": \"others\"\n",
    "}\n",
    "SUB_FILE = ['axis1', 'axis2', 'axis3', 'axis4']\n",
    "\n",
    "    \n",
    "data_pos_train, data_pos_test, _, _ = train_test_split(data_pos, data_pos, test_size=0.3)\n",
    "data_neg_train, data_neg_test, _, _ = train_test_split(data_neg, data_neg, test_size=0.3)\n",
    "#     print(data_pos_train)\n",
    "#     print(data_pos_test)\n",
    "#     print(data_neg_train)\n",
    "#     print(data_neg_test)\n",
    "data_train = data_pos_train.append(data_neg_train)\n",
    "data_test = data_pos_test.append(data_neg_test)\n",
    "data = data_train.append(data_test)\n",
    "data_train.to_csv('csv/data_train.csv')\n",
    "data_test.to_csv('csv/data_test.csv')\n",
    "\n",
    "# EXAM_SLICE = 200\n",
    "CLASSES = len(set([label for label in ['POSITIVE', 'NEGATIVE']]))\n",
    "EPOCHS = 25\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "IMG_CHANNELS = 3\n",
    "SELECTED_MODEL = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(set_number, cur_subfile, data_train, data_test):\n",
    "    dfs = []\n",
    "    train_images = {\"id\": [], \"label\": []}\n",
    "    validation_images = {\"id\": [], \"label\": []}\n",
    "#     subset_imgs_folder_val = LIST_IMG_FOLDERS[set_number * 4:(set_number+1) * 4]\n",
    "    \n",
    "    LIST_IMG_FOLDERS = data['nome'].to_list()\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "#     print(TRAIN_IMG_FOLDERS_SLICE)\n",
    "#     print(VALIDATION_IMG_FOLDERS_SLICE)\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            dic[\"id\"].extend(imgs_filename)\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "    train_df.to_csv('train_df_'+str(set_number)+'.csv', index=False)\n",
    "    validation_df.to_csv('validation_df_'+str(set_number)+'.csv', index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"all\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(train_images[\"id\"])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(train_images[\"label\"])\n",
    "    for path, target in zip(train_images[\"id\"], train_images[\"label\"]):\n",
    "        if target!=show and show!=\"all\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\"all\":\"All Classifications's\",\n",
    "             \"healthy\":\"Healthy\",\n",
    "             \"covid\":\"Covid-19\"}\n",
    "    plt.title(\"100 Samples of {} Patients of the training set\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_gallery(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "#     fill_mode='constant',\n",
    "#     cval=0\n",
    "    )\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        class_mode=class_mode,\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_data_set() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cf9f9446bcc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSUB_FILE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexample_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_data_set() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "train_df, validation_df = get_data_set(0, SUB_FILE[0], data_train, data_test)\n",
    "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "example_generator = get_data_generator(example_df, \"id\", \"label\", class_mode = \"categorical\")\n",
    "plt.figure(figsize = (12,12))\n",
    "for i in range(0, 9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        for X_batch, Y_batch in example_generator:\n",
    "            image = X_batch[0]\n",
    "            plt.imshow(image)\n",
    "            break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    with tf.device('/GPU:0'):\n",
    "#         inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#         s = tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n",
    "        \n",
    "        classifier = tf.keras.Sequential()\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "#         classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "#         classifier.add(Convolution2D(64, (3, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.Conv2D(64, (3, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(128, (3, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(256, (3,3), activation = 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        classifier.add(tf.keras.layers.Dense(units= 512, activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "        classifier.add(tf.keras.layers.Dense(units= 3, activation= 'sigmoid'))\n",
    "\n",
    "        classifier.compile(optimizer= 'adam', loss= 'categorical_crossentropy' ,metrics= ['accuracy'])\n",
    "        classifier.summary()\n",
    "\n",
    "        return(classifier, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_alexnet():\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(96, kernel_size=(11,11), strides= 4, padding= 'valid', activation= 'relu', \n",
    "                                         input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), kernel_initializer= 'he_normal'))\n",
    "        \n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', \n",
    "                                               data_format= None))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(256, kernel_size=(5,5), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "        \n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', \n",
    "                                               data_format= None)) \n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(384, kernel_size=(3,3), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(384, kernel_size=(3,3), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(256, kernel_size=(3,3), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', \n",
    "                                               data_format= None))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(4096, activation= 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(4096, activation= 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(1000, activation= 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(units=3, activation= 'softmax'))\n",
    "\n",
    "        model.compile(optimizer= tf.keras.optimizers.Adam(0.001), loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return(model, 'alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg16():\n",
    "        with tf.device('/GPU:0'):\n",
    "            conv_base = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "            conv_base.trainable = True\n",
    "            set_trainable = False\n",
    "            for layer in conv_base.layers:\n",
    "                if layer.name == 'conv3_block1_1_conv':\n",
    "                    set_trainable = True\n",
    "                if set_trainable:\n",
    "                    layer.trainable = True\n",
    "                else:\n",
    "                    layer.trainable = False\n",
    "\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(conv_base)\n",
    "            model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "            model.add(tf.keras.layers.Dense(units=2, activation = 'sigmoid'))\n",
    "\n",
    "            model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            return (model, 'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, validation_df, epochs, callbacks=[]):\n",
    "    batch_size = 16\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "    validation_generator = get_data_generator(validation_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "\n",
    "    step_size_train = train_generator.n // train_generator.batch_size\n",
    "    step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = train_generator.n // 2\n",
    "        step_size_validation = validation_generator.n // 2\n",
    "        \n",
    "    history = model.fit(train_generator, # X_Train\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=callbacks\n",
    "   )\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(history, sub_folder, kfold, sel_model):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + FOLDER_TEST + '/' + sub_folder + '/' + kfold + 'acc_'  + sel_model,\n",
    "                pad_inches=0.1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('images/' + FOLDER_TEST + '/' + sub_folder + '/' + kfold + 'loss_'  + sel_model, \n",
    "                orientation='portrait', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cur_subfolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-69a33f311d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_subfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcur_subfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSUB_FILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     for set_number in [0, 1, 2, 3, 4]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n\\nTEST #\\n====='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_subfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"first\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cur_subfolder' is not defined"
     ]
    }
   ],
   "source": [
    "for cur_subfolder in SUB_FILE:\n",
    "#     for set_number in [0, 1, 2, 3, 4]:\n",
    "    train_df, validation_df = get_data_set(\"first\", cur_subfolder, data_train, data_test)\n",
    "    print('\\n\\n\\nTEST #\\n=====')\n",
    "    print(cur_subfolder, \"first\")\n",
    "    model, SELECTED_MODEL = get_model_vgg16()\n",
    "    history = train_model(model, train_df, validation_df, EPOCHS)\n",
    "    plot_results(history, cur_subfolder, str(\"first\"), SELECTED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
