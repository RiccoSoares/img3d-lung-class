{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read exams data and initial parameters\n",
    "data = pd.read_csv('csv/exames.csv')\n",
    "data['int_covid'] = 0\n",
    "data.loc[data['covid'] == 'POSITIVE', 'int_covid'] = 1\n",
    "\n",
    "FOLDER_TEST = \"exame-pulmao\"\n",
    "TRAIN_IMG_SRC_FOLDER = \"/ssd/share/Classificacao/Abordagem3D-Comba/input/\" + FOLDER_TEST\n",
    "\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/ssd/share/Classificacao/Abordagem3D-Comba/input/\" + FOLDER_TEST\n",
    "SUB_FILE = ['axis1', 'axis2', 'axis3', 'axis4']\n",
    "\n",
    "CLASSES = len(set([label for label in ['POSITIVE', 'NEGATIVE']]))\n",
    "EPOCHS = 5\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "IMG_CHANNELS = 3\n",
    "SELECTED_MODEL = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split into Data for training/validation, and TEST, save as files'''\n",
    "def get_dataset_trainval_test(data, filename_complement):\n",
    "    data_pos = data[data.covid == 'POSITIVE']\n",
    "    data_neg = data[data.covid == 'NEGATIVE']\n",
    "\n",
    "    data_pos_train, data_pos_test, _, _ = train_test_split(data_pos, data_pos, test_size=0.05)\n",
    "    data_neg_train, data_neg_test, _, _ = train_test_split(data_neg, data_neg, test_size=0.1)\n",
    "\n",
    "    # Data for TEST\n",
    "    data_test = data_pos_test.append(data_neg_test)\n",
    "    # Data for training/val\n",
    "    data_tv = data_pos_train.append(data_neg_train)\n",
    "\n",
    "    data_tv.to_csv('csv/data_tv_'+filename_complement+'.csv')\n",
    "    data_test.to_csv('csv/data_test_'+filename_complement+'.csv')\n",
    "    return(data_tv, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(set_number, cur_subfile, data_train, data_test):\n",
    "    dfs = []\n",
    "    train_images = {\"id\": [], \"label\": []}\n",
    "    validation_images = {\"id\": [], \"label\": []}\n",
    "#     subset_imgs_folder_val = LIST_IMG_FOLDERS[set_number * 4:(set_number+1) * 4]\n",
    "    \n",
    "    LIST_IMG_FOLDERS = data['nome'].to_list()\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "#     print(TRAIN_IMG_FOLDERS_SLICE)\n",
    "#     print(VALIDATION_IMG_FOLDERS_SLICE)\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            dic[\"id\"].extend(imgs_filename)\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "    train_df.to_csv('train_df_'+str(set_number)+'.csv', index=False)\n",
    "    validation_df.to_csv('validation_df_'+str(set_number)+'.csv', index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"all\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(train_images[\"id\"])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(train_images[\"label\"])\n",
    "    for path, target in zip(train_images[\"id\"], train_images[\"label\"]):\n",
    "        if target!=show and show!=\"all\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\"all\":\"All Classifications's\",\n",
    "             \"healthy\":\"Healthy\",\n",
    "             \"covid\":\"Covid-19\"}\n",
    "    plt.title(\"100 Samples of {} Patients of the training set\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_gallery(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "#     fill_mode='constant',\n",
    "#     cval=0\n",
    "    )\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        class_mode=class_mode,\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    with tf.device('/GPU:0'):\n",
    "#         inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#         s = tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n",
    "        \n",
    "        classifier = tf.keras.Sequential()\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "#         classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "#         classifier.add(Convolution2D(64, (3, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.Conv2D(64, (3, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(128, (3, 3), activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Conv2D(256, (3,3), activation = 'relu'))\n",
    "        classifier.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        classifier.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        classifier.add(tf.keras.layers.Dense(units= 512, activation= 'relu'))\n",
    "        classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "        classifier.add(tf.keras.layers.Dense(units= 2, activation= 'sigmoid'))\n",
    "\n",
    "        classifier.compile(optimizer= 'adam', loss= 'categorical_crossentropy' ,metrics= ['accuracy'])\n",
    "        classifier.summary()\n",
    "\n",
    "        return(classifier, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_alexnet():\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(96, kernel_size=(11,11), strides= 4, padding= 'valid', activation= 'relu', \n",
    "                                         input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), kernel_initializer= 'he_normal'))\n",
    "        \n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', \n",
    "                                               data_format= None))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(256, kernel_size=(5,5), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "        \n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', \n",
    "                                               data_format= None)) \n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(384, kernel_size=(3,3), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(384, kernel_size=(3,3), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(256, kernel_size=(3,3), strides= 1, padding= 'same', activation= 'relu',\n",
    "                                         kernel_initializer= 'he_normal'))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', \n",
    "                                               data_format= None))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(4096, activation= 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(4096, activation= 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(1000, activation= 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(units=2, activation= 'softmax'))\n",
    "\n",
    "        model.compile(optimizer= tf.keras.optimizers.Adam(0.001), loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return(model, 'alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg16():\n",
    "        with tf.device('/GPU:0'):\n",
    "            conv_base = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "            conv_base.trainable = True\n",
    "            set_trainable = False\n",
    "            for layer in conv_base.layers:\n",
    "                if layer.name == 'block1_conv1':\n",
    "                    set_trainable = True\n",
    "                if set_trainable:\n",
    "                    layer.trainable = True\n",
    "                else:\n",
    "                    layer.trainable = False\n",
    "\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(conv_base)\n",
    "            model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "            model.add(tf.keras.layers.Dense(units=2, activation = 'sigmoid'))\n",
    "\n",
    "            model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            return (model, 'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, validation_df, epochs, fold, axis):\n",
    "    batch_size = 16\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "    validation_generator = get_data_generator(validation_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "\n",
    "    step_size_train = train_generator.n // train_generator.batch_size\n",
    "    step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = train_generator.n // 2\n",
    "        step_size_validation = validation_generator.n // 2\n",
    "        \n",
    "        \n",
    "    # callbacks, save each time\n",
    "    \n",
    "    # Include the epoch in the file name (uses `str.format`)\n",
    "    if not os.path.exists(\"training/\"): \n",
    "        os.mkdir(\"training/\")\n",
    "    if not os.path.exists(\"training/\"+SELECTED_MODEL+\"/\"): \n",
    "        os.mkdir(\"training/\"+SELECTED_MODEL+\"/\")\n",
    "    if not os.path.exists(\"training/\"+SELECTED_MODEL+\"/\"+str(fold)+\"fold/\"): \n",
    "        os.mkdir(\"training/\"+SELECTED_MODEL+\"/\"+str(fold)+\"fold/\")\n",
    "    if not os.path.exists(\"training/\"+SELECTED_MODEL+\"/\"+str(fold)+\"fold/\"+axis+\"/\"): \n",
    "        os.mkdir(\"training/\"+SELECTED_MODEL+\"/\"+str(fold)+\"fold/\"+axis+\"/\")\n",
    "        \n",
    "        \n",
    "    checkpoint_path = \"training/\"+SELECTED_MODEL+\"/\"+str(fold)+\"fold/\"+axis+\"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 5 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        period=1)\n",
    "        \n",
    "    history = model.fit(train_generator, # X_Train\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=cp_callbacks\n",
    "                       )\n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = 'models/'+SELECTED_MODEL+'_history_'+str(fold)+'_'+axis+'.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    \n",
    "    # Save classes\n",
    "    np.save('models/'+SELECTED_MODEL+'_legend_'+str(fold)+'_'+axis, train_generator.class_indices)\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(history, sub_folder, kfold, sel_model):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + FOLDER_TEST + '/' + sub_folder + '/' + kfold + 'acc_'  + sel_model,\n",
    "                pad_inches=0.1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('images/' + FOLDER_TEST + '/' + sub_folder + '/' + kfold + 'loss_'  + sel_model, \n",
    "                orientation='portrait', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=4, random_state=None, shuffle=True)\n",
      "\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Train fold with 5822 images\n",
      "label\n",
      "NEGATIVE    1394\n",
      "POSITIVE    4428\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 1968 images\n",
      "label\n",
      "NEGATIVE     574\n",
      "POSITIVE    1394\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis1\n",
      "=====\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 6, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 5822 validated image filenames belonging to 2 classes.\n",
      "Found 1968 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 330s 909ms/step - loss: 0.1241 - accuracy: 0.9487 - val_loss: 0.5092 - val_accuracy: 0.8694\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 295s 812ms/step - loss: 0.0233 - accuracy: 0.9962 - val_loss: 0.6677 - val_accuracy: 0.8720\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 295s 813ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 1.1622 - val_accuracy: 0.8247\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 295s 813ms/step - loss: 0.0151 - accuracy: 0.9986 - val_loss: 0.8969 - val_accuracy: 0.8516\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 295s 812ms/step - loss: 0.0103 - accuracy: 0.9986 - val_loss: 1.3973 - val_accuracy: 0.8592\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fold with 5822 images\n",
      "label\n",
      "NEGATIVE    1394\n",
      "POSITIVE    4428\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 1968 images\n",
      "label\n",
      "NEGATIVE     574\n",
      "POSITIVE    1394\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis2\n",
      "=====\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 6, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 14,715,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 5822 validated image filenames belonging to 2 classes.\n",
      "Found 1968 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 304s 838ms/step - loss: 0.1181 - accuracy: 0.9526 - val_loss: 0.5481 - val_accuracy: 0.8440\n",
      "Epoch 2/5\n",
      "346/363 [===========================>..] - ETA: 10s - loss: 0.0198 - accuracy: 0.9971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-24498bfa44e8>\", line 19, in <module>\n",
      "    history = train_model(model, train_df, validation_df, EPOCHS, n_fold, cur_subfolder)\n",
      "  File \"<ipython-input-12-2df9ce8a0892>\", line 13, in train_model\n",
      "    history = model.fit(train_generator, # X_Train\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1843, in _filtered_call\n",
      "    return self._call_flat(\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1923, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 545, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/users/nmlromero/.conda/envs/env-cnn/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-24498bfa44e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSELECTED_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_vgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_subfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2df9ce8a0892>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_df, validation_df, epochs, fold, axis, callbacks)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     history = model.fit(train_generator, # X_Train\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-cnn/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Split into training/validation and TEST\n",
    "data_tv, data_test = get_dataset_trainval_test(data, 'complement')\n",
    "\n",
    "X = data_tv.index.to_list()\n",
    "y = data_tv['int_covid'].to_list()\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "n_fold = 0\n",
    "for train_index, validation_index in skf.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "    n_fold += 1\n",
    "    print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "    for cur_subfolder in SUB_FILE:\n",
    "        train_df, validation_df = get_data_set(str(n_fold)+\"fold\", cur_subfolder, \n",
    "                                               data_tv.iloc[train_index, :], data_tv.iloc[validation_index, :])\n",
    "        print('\\n'+cur_subfolder+'\\n=====')\n",
    "        model, SELECTED_MODEL = get_model_vgg16()\n",
    "        history = train_model(model, train_df, validation_df, EPOCHS, n_fold, cur_subfolder)\n",
    "        \n",
    "        #Plot Results\n",
    "        plot_results(history, cur_subfolder, str(n_fold)+\"fold\", SELECTED_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_by_patient(model, patients):\n",
    "    results = []\n",
    "    for p in patients:\n",
    "        curr_dir = VALIDATION_IMG_SRC_FOLDER + '/' + p + '/'\n",
    "        imgs_filename = sorted(os.listdir(curr_dir))\n",
    "        test_filenames = imgs_filename[:]\n",
    "        test_df = pd.DataFrame({\n",
    "                'filename': test_filenames\n",
    "            })\n",
    "        nb_samples = test_df.shape[0]\n",
    "\n",
    "        test_gen = ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_gen.flow_from_dataframe(\n",
    "                test_df, \n",
    "                curr_dir, \n",
    "                x_col='filename',\n",
    "                y_col=None,\n",
    "                class_mode=None,\n",
    "                target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                batch_size=16,\n",
    "                shuffle=False\n",
    "        )\n",
    "\n",
    "        predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))\n",
    "        test_df['category'] = [int(round(p[0])) for p in predict]\n",
    "        results.append(test_df)\n",
    "\n",
    "    for i,test_df in enumerate(results):\n",
    "        print('Patient number: ', patients[i])\n",
    "        if os.path.isfile('vgg_legend.npy'):\n",
    "            print('loading label legend file')\n",
    "            class_indices = np.load('vgg_legend.npy', allow_pickle=True).item()\n",
    "            class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "            test_df['category'] = test_df['category'].replace(class_indices)\n",
    "        print(test_df['category'].value_counts())\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, validation_df = get_data_set(0, SUB_FILE[0], data_train, data_test)\n",
    "# example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "# example_generator = get_data_generator(example_df, \"id\", \"label\", class_mode = \"categorical\")\n",
    "# plt.figure(figsize = (12,12))\n",
    "# for i in range(0, 9):\n",
    "#         plt.subplot(3, 3, i+1)\n",
    "#         for X_batch, Y_batch in example_generator:\n",
    "#             image = X_batch[0]\n",
    "#             plt.imshow(image)\n",
    "#             break\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
